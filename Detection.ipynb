{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c224fc",
   "metadata": {},
   "source": [
    "### Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e203f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydicom\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install opencv_python\n",
    "# !pip install tqdm\n",
    "# !pip install scikit-image\n",
    "# !pip install nibabel\n",
    "# !pip install scikit-image\n",
    "# !pip install gdcm\n",
    "# !pip install pylibjpeg\n",
    "# !pip install pylibjpeg pylibjpeg-libjpeg pydicom[gdcm]\n",
    "# !pip install \"dask[dataframe]\"\n",
    "# !pip install imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8b020",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7fdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid', font_scale=1.6)\n",
    "import cv2\n",
    "import os\n",
    "from os import listdir\n",
    "import re\n",
    "import gc\n",
    "import pydicom\n",
    "import datetime\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import itertools\n",
    "from skimage import measure \n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import dask.array as da\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f92d5b7",
   "metadata": {},
   "source": [
    "### Load Segmentation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5589446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_NIfTI(path):\n",
    "    mask = nib.load(path)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    seg = mask.get_fdata()\n",
    "    \n",
    "    # Align orientation with images\n",
    "    seg = seg[:, ::-1, ::-1].transpose(2, 1, 0)\n",
    "    \n",
    "    return seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff97a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting patient with mask\n",
    "seg_paths = glob(f'G:/Data/Spine_Data/segmentations/*')\n",
    "training_patient=[]\n",
    "for path in seg_paths:\n",
    "    training_patient.append((path.rsplit(\"\\\\\",1)[-1])[:-4])#Patient with mask present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2bb8dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 512, 512)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example segment image\n",
    "path_mask=f\"G:/Data/Spine_Data/segmentations/{training_patient[-7]}.nii\"\n",
    "patient_mask=load_NIfTI(path_mask)\n",
    "\n",
    "patient_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fba7cb",
   "metadata": {},
   "source": [
    "### Apply windowing to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91e83a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_windowing(image, window_width, window_level):\n",
    "    # Apply windowing to the image\n",
    "    min_value = window_level - (window_width // 2)\n",
    "    max_value = window_level + (window_width // 2)\n",
    "    windowed_image = np.clip(image, min_value, max_value)\n",
    "    windowed_image = (windowed_image - min_value) / (max_value - min_value)\n",
    "    windowed_image = (windowed_image * 255).astype(np.uint8)\n",
    "    return windowed_image\n",
    "\n",
    "# ...\n",
    "\n",
    "# Inside the loop\n",
    "\n",
    "# Apply windowing to the image slice range\n",
    "# image_slice_range = apply_windowing(image_slice_range, window_width, window_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a147c2",
   "metadata": {},
   "source": [
    "## Creat bondingbox from Segmentation Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c211c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "from skimage.measure import label, regionprops\n",
    "import imageio\n",
    "\n",
    "start = 0\n",
    "\n",
    "# Create the output directories for saving images and bounding boxes if they don't exist\n",
    "images_directory = \"images\"\n",
    "os.makedirs(images_directory, exist_ok=True)\n",
    "bounding_boxes_directory = \"labels\"\n",
    "os.makedirs(bounding_boxes_directory, exist_ok=True)\n",
    "\n",
    "for i in range(start, start + 40):\n",
    "    patient_ID = training_patient[i]\n",
    "    \n",
    "    # Load segmentation mask\n",
    "    mask = load_NIfTI(f\"G:/Data/Spine_Data/segmentations/{patient_ID}.nii\")\n",
    "    \n",
    "    # Select specific slices from the mask\n",
    "    mask_slice_range = mask[:]\n",
    "    \n",
    "    # Get unique component labels in the mask\n",
    "    component_labels = np.unique(mask_slice_range)\n",
    "    \n",
    "    # Iterate over each component label\n",
    "    for label_value in component_labels:\n",
    "        # Exclude background label (0)\n",
    "        if label_value == 0:\n",
    "            continue\n",
    "        \n",
    "        # Assign class based on label value\n",
    "        obj_class = int(label_value)\n",
    "        \n",
    "        # Skip labels greater than 7\n",
    "        if obj_class > 7:\n",
    "            continue\n",
    "        \n",
    "        # Create a binary mask for the current label\n",
    "        binary_mask = (mask_slice_range == label_value).astype(np.uint8)\n",
    "        \n",
    "        # Label connected components in the binary mask\n",
    "        labeled_mask = label(binary_mask)\n",
    "        \n",
    "        # Find the components with the current label\n",
    "        props = regionprops(labeled_mask)\n",
    "        \n",
    "        # Load patient scan\n",
    "        patient_scan = load_scan(f\"G:/Data/Spine_Data/train_images/{patient_ID}\")\n",
    "        \n",
    "        # Select specific slices from the scan\n",
    "        image_slice_range = get_pixels_hu(patient_scan)[:]\n",
    "        \n",
    "        # Apply windowing to the image slice range\n",
    "        window_width = 2000\n",
    "        window_level = 500\n",
    "        image_slice_range = apply_windowing(image_slice_range, window_width, window_level)\n",
    "        \n",
    "        # Save each image slice as PNG and corresponding bounding boxes\n",
    "        for idx, image_slice in enumerate(image_slice_range):\n",
    "            current_slice_binary_mask = binary_mask[idx]\n",
    "            \n",
    "            # Check if the binary mask has non-zero values\n",
    "            if np.count_nonzero(current_slice_binary_mask) == 0:\n",
    "                continue\n",
    "            \n",
    "            image_filename = f\"{patient_ID}_{idx}.png\"\n",
    "            image_filepath = os.path.join(images_directory, image_filename)  # Update the desired output directory\n",
    "            imageio.imwrite(image_filepath, image_slice)\n",
    "            \n",
    "            # Calculate bounding box coordinates for each object in the current image slice\n",
    "            labeled_objects = label(current_slice_binary_mask)\n",
    "            object_labels = np.unique(labeled_objects)\n",
    "            \n",
    "            for object_label in object_labels:\n",
    "                if object_label == 0:\n",
    "                    continue\n",
    "                \n",
    "                object_mask = (labeled_objects == object_label).astype(np.uint8)\n",
    "                non_zero_pixels = np.nonzero(object_mask)\n",
    "                \n",
    "                if non_zero_pixels[0].size == 0:\n",
    "                    continue\n",
    "                \n",
    "#                 min_col = np.min(non_zero_pixels[1])\n",
    "#                 min_row = np.min(non_zero_pixels[0])\n",
    "#                 max_col = np.max(non_zero_pixels[1])\n",
    "#                 max_row = np.max(non_zero_pixels[0])\n",
    "                margin = 10\n",
    "                min_col = np.min(non_zero_pixels[1])\n",
    "                min_row = np.min(non_zero_pixels[0])\n",
    "                max_col = np.max(non_zero_pixels[1]) + margin\n",
    "                max_row = np.max(non_zero_pixels[0]) + margin\n",
    "\n",
    "                # Ensure the bounding box coordinates are within the image dimensions\n",
    "                min_col = max(0, min_col)\n",
    "                min_row = max(0, min_row)\n",
    "                max_col = min(image_slice.shape[1] - 1, max_col)\n",
    "                max_row = min(image_slice.shape[0] - 1, max_row)\n",
    "\n",
    "                # Skip bounding boxes with class values greater than 7\n",
    "                if obj_class > 7:\n",
    "                    continue\n",
    "                \n",
    "                # Save bounding box coordinates in TXT file\n",
    "                txt_filename = f\"{patient_ID}_{idx}.txt\"\n",
    "                txt_filepath = os.path.join(bounding_boxes_directory, txt_filename)  # Update the desired output directory\n",
    "\n",
    "                \n",
    "                with open(txt_filepath, \"w\") as txt_file:\n",
    "                    txt_file.write(f\"{obj_class} {min_col} {min_row} {max_col} {max_row}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9cec96",
   "metadata": {},
   "source": [
    "### Normalized Bondingbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df32f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Folder path containing the label files\n",
    "# labels_folder = \"labels\"\n",
    "\n",
    "# # Image dimensions\n",
    "# image_width = 512  # Width of the image in pixels\n",
    "# image_height = 512  # Height of the image in pixels\n",
    "\n",
    "# # Iterate over the label files in the folder\n",
    "# for filename in os.listdir(labels_folder):\n",
    "#     if filename.endswith(\".txt\"):\n",
    "#         label_file = os.path.join(labels_folder, filename)\n",
    "\n",
    "#         # Read the label file\n",
    "#         with open(label_file, \"r\") as file:\n",
    "#             lines = file.readlines()\n",
    "\n",
    "#         # Normalize the bounding box coordinates\n",
    "#         normalized_lines = []\n",
    "#         for line in lines:\n",
    "#             parts = line.strip().split(\" \")\n",
    "#             class_label = parts[0]\n",
    "#             x_min, y_min, width, height = map(float, parts[1:])\n",
    "\n",
    "#             # Normalize the bounding box coordinates\n",
    "#             normalized_x_min = x_min / image_width\n",
    "#             normalized_y_min = y_min / image_height\n",
    "#             normalized_width = width / image_width\n",
    "#             normalized_height = height / image_height\n",
    "\n",
    "#             # Append the normalized coordinates with the class information to the new list\n",
    "#             normalized_lines.append(f\"{class_label} {normalized_x_min} {normalized_y_min} {normalized_width} {normalized_height}\\n\")\n",
    "\n",
    "#         # Save the normalized bounding box coordinates back to the label file\n",
    "#         with open(label_file, \"w\") as file:\n",
    "#             file.writelines(normalized_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92281c6",
   "metadata": {},
   "source": [
    "### Convert class from 1 to 7 to 0 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f1db349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Folder path containing the label files\n",
    "# labels_folder = \"F:/PythonEn/Code/Datav8/val/labels\"\n",
    "\n",
    "# Iterate over the label files in the folder\n",
    "for filename in os.listdir(labels_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        label_file = os.path.join(labels_folder, filename)\n",
    "\n",
    "        # Read the label file\n",
    "        with open(label_file, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Convert the class labels\n",
    "        converted_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split(\" \")\n",
    "            class_label = int(parts[0]) - 1  # Convert class from 1 to 7 to 0 to 6\n",
    "\n",
    "            # Append the converted class label with the remaining parts to the new list\n",
    "            converted_lines.append(f\"{class_label} {' '.join(parts[1:])}\\n\")\n",
    "\n",
    "        # Save the converted lines back to the label file\n",
    "        with open(label_file, \"w\") as file:\n",
    "            file.writelines(converted_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817e7466",
   "metadata": {},
   "source": [
    "### Yolo v5 & v8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96df8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d53dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60e20b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6e3950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cc86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd yolov5 & pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf5f61b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54236a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Change to the directory where requirements.txt is located\n",
    "# os.chdir(\"F:\\PythonEn\\Code\\yolov5\")\n",
    "\n",
    "# # Install the requirements\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd971b3",
   "metadata": {},
   "source": [
    "### Data Preparation Yolov5 Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f833d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images are :  7337\n",
      "Validation images are :  1834\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset in train and val folder.\n",
    "import os\n",
    "from random import choice\n",
    "import shutil\n",
    "\n",
    "#arrays to store file names\n",
    "imgs =[]\n",
    "xmls =[]\n",
    "\n",
    "#setup dir names\n",
    "trainPath = 'F:/PythonEn/Code/yolov5/dataset/images/train'\n",
    "valPath = 'F:/PythonEn/Code/yolov5/dataset/images/val'\n",
    "crsPath = 'F:/PythonEn/Code/yolov5/image/' #dir where images and annotations stored\n",
    "\n",
    "#setup ratio (val ratio = rest of the files in origin dir after splitting into train and test)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "\n",
    "#total count of imgs\n",
    "totalImgCount = len(os.listdir(crsPath))/2\n",
    "\n",
    "#soring files to corresponding arrays\n",
    "for (dirname, dirs, files) in os.walk(crsPath):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):\n",
    "            xmls.append(filename)\n",
    "        else:\n",
    "            imgs.append(filename)\n",
    "\n",
    "\n",
    "#counting range for cycles\n",
    "countForTrain = int(len(imgs)*train_ratio)\n",
    "countForVal = int(len(imgs)*val_ratio)\n",
    "print(\"training images are : \",countForTrain)\n",
    "print(\"Validation images are : \",countForVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0f4884a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:/PythonEn/Code/yolov5/dataset/images/val\\\\image'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainimagePath = 'F:/PythonEn/Code/yolov5/dataset/images/train'\n",
    "trainlabelPath = 'F:/PythonEn/Code/yolov5/dataset/labels/train'\n",
    "valimagePath = 'F:/PythonEn/Code/yolov5/dataset/images/val'\n",
    "vallabelPath = 'F:/PythonEn/Code/yolov5/dataset/labels/val'\n",
    "#cycle for train dir\n",
    "for x in range(countForTrain):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(trainimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(trainlabelPath, fileXml))\n",
    "\n",
    "\n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "\n",
    "\n",
    "#cycle for test dir   \n",
    "for x in range(countForVal):\n",
    "\n",
    "    fileJpg = choice(imgs) # get name of random image from origin dir\n",
    "    fileXml = fileJpg[:-4] +'.txt' # get name of corresponding annotation file\n",
    "\n",
    "    #move both files into train dir\n",
    "    #shutil.move(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    #shutil.move(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    shutil.copy(os.path.join(crsPath, fileJpg), os.path.join(valimagePath, fileJpg))\n",
    "    shutil.copy(os.path.join(crsPath, fileXml), os.path.join(vallabelPath, fileXml))\n",
    "    \n",
    "    #remove files from arrays\n",
    "    imgs.remove(fileJpg)\n",
    "    xmls.remove(fileXml)\n",
    "\n",
    "#rest of files will be validation files, so rename origin dir to val dir\n",
    "#os.rename(crsPath, valPath)\n",
    "shutil.move(crsPath, valPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f7004",
   "metadata": {},
   "source": [
    "### Yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d897390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall yolov5\n",
    "# !pip install yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ff256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5df6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5 && python train.py --img 512 --batch 4 --epochs 3 --data custom_data.yaml --weights yolov5m.pt --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bcb60",
   "metadata": {},
   "source": [
    "### Yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b64951ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.8.6 torch-1.8.1+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Setup complete  (12 CPUs, 15.8 GB RAM, 65.6/431.5 GB disk)\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics==8.0.20\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c14f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff085b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c17f2637",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8m.pt to yolov8m.pt...\n",
      "\n",
      "  0%|          | 0.00/49.7M [00:00<?, ?B/s]\n",
      "  1%|1         | 536k/49.7M [00:00<00:10, 5.02MB/s]\n",
      "  2%|2         | 1.01M/49.7M [00:00<00:10, 4.82MB/s]\n",
      "  3%|3         | 1.54M/49.7M [00:00<00:10, 4.95MB/s]\n",
      "  5%|4         | 2.41M/49.7M [00:00<00:07, 6.28MB/s]\n",
      "  7%|7         | 3.59M/49.7M [00:00<00:05, 8.22MB/s]\n",
      "  9%|9         | 4.60M/49.7M [00:00<00:05, 8.72MB/s]\n",
      " 11%|#         | 5.44M/49.7M [00:00<00:05, 8.49MB/s]\n",
      " 13%|#2        | 6.33M/49.7M [00:00<00:05, 8.50MB/s]\n",
      " 14%|#4        | 7.14M/49.7M [00:01<00:09, 4.70MB/s]\n",
      " 16%|#5        | 7.77M/49.7M [00:01<00:10, 4.14MB/s]\n",
      " 17%|#6        | 8.30M/49.7M [00:01<00:10, 4.31MB/s]\n",
      " 18%|#7        | 8.83M/49.7M [00:01<00:09, 4.48MB/s]\n",
      " 19%|#8        | 9.34M/49.7M [00:01<00:09, 4.57MB/s]\n",
      " 20%|##        | 10.0M/49.7M [00:01<00:08, 5.06MB/s]\n",
      " 22%|##1       | 10.8M/49.7M [00:02<00:06, 5.87MB/s]\n",
      " 23%|##3       | 11.6M/49.7M [00:02<00:06, 6.55MB/s]\n",
      " 25%|##5       | 12.6M/49.7M [00:02<00:05, 7.38MB/s]\n",
      " 28%|##7       | 13.8M/49.7M [00:02<00:04, 8.42MB/s]\n",
      " 30%|###       | 15.0M/49.7M [00:02<00:03, 9.33MB/s]\n",
      " 33%|###2      | 16.2M/49.7M [00:02<00:03, 10.0MB/s]\n",
      " 35%|###4      | 17.4M/49.7M [00:02<00:03, 10.4MB/s]\n",
      " 37%|###7      | 18.5M/49.7M [00:02<00:03, 10.7MB/s]\n",
      " 40%|###9      | 19.7M/49.7M [00:02<00:02, 10.8MB/s]\n",
      " 42%|####1     | 20.9M/49.7M [00:02<00:02, 10.9MB/s]\n",
      " 44%|####4     | 21.9M/49.7M [00:03<00:02, 10.6MB/s]\n",
      " 46%|####6     | 22.9M/49.7M [00:03<00:02, 9.96MB/s]\n",
      " 48%|####8     | 23.9M/49.7M [00:03<00:03, 9.00MB/s]\n",
      " 50%|####9     | 24.8M/49.7M [00:03<00:03, 7.85MB/s]\n",
      " 51%|#####1    | 25.6M/49.7M [00:03<00:03, 7.79MB/s]\n",
      " 53%|#####2    | 26.3M/49.7M [00:03<00:03, 7.67MB/s]\n",
      " 55%|#####4    | 27.1M/49.7M [00:03<00:03, 7.62MB/s]\n",
      " 56%|#####6    | 28.1M/49.7M [00:03<00:02, 8.02MB/s]\n",
      " 59%|#####8    | 29.1M/49.7M [00:04<00:02, 8.60MB/s]\n",
      " 61%|######    | 30.2M/49.7M [00:04<00:02, 9.13MB/s]\n",
      " 63%|######3   | 31.3M/49.7M [00:04<00:02, 9.57MB/s]\n",
      " 65%|######4   | 32.3M/49.7M [00:04<00:01, 9.49MB/s]\n",
      " 67%|######6   | 33.3M/49.7M [00:04<00:01, 9.47MB/s]\n",
      " 69%|######8   | 34.3M/49.7M [00:04<00:01, 9.62MB/s]\n",
      " 71%|#######1  | 35.4M/49.7M [00:04<00:01, 9.92MB/s]\n",
      " 73%|#######3  | 36.3M/49.7M [00:04<00:01, 9.69MB/s]\n",
      " 75%|#######5  | 37.3M/49.7M [00:04<00:01, 9.57MB/s]\n",
      " 77%|#######6  | 38.2M/49.7M [00:05<00:01, 9.61MB/s]\n",
      " 79%|#######9  | 39.3M/49.7M [00:05<00:01, 9.84MB/s]\n",
      " 81%|########1 | 40.4M/49.7M [00:05<00:00, 10.0MB/s]\n",
      " 83%|########3 | 41.4M/49.7M [00:05<00:00, 10.1MB/s]\n",
      " 85%|########5 | 42.5M/49.7M [00:05<00:00, 10.0MB/s]\n",
      " 88%|########7 | 43.5M/49.7M [00:05<00:00, 10.0MB/s]\n",
      " 90%|########9 | 44.6M/49.7M [00:05<00:00, 10.2MB/s]\n",
      " 92%|#########1| 45.7M/49.7M [00:05<00:00, 10.2MB/s]\n",
      " 94%|#########3| 46.7M/49.7M [00:05<00:00, 10.0MB/s]\n",
      " 96%|#########5| 47.6M/49.7M [00:06<00:00, 9.76MB/s]\n",
      " 98%|#########7| 48.6M/49.7M [00:06<00:00, 9.49MB/s]\n",
      "100%|##########| 49.7M/49.7M [00:06<00:00, 9.90MB/s]\n",
      "100%|##########| 49.7M/49.7M [00:06<00:00, 8.36MB/s]\n",
      "\n",
      "Ultralytics YOLOv8.0.20  Python-3.8.6 torch-1.8.1+cu111 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.yaml, data=custom.yaml, epochs=2, patience=50, batch=16, imgsz=640, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=False, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.1, copy_paste=0.1, cfg=None, v5loader=False, save_dir=runs\\detect\\train\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Muhammad Yaseen\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\Muhammad Yaseen\\AppData\\Local\\Programs\\Python\\Python38\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"F:\\PythonEn\\yolo\\Scripts\\yolo.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\ultralytics\\yolo\\cfg\\__init__.py\", line 249, in entrypoint\n",
      "    getattr(model, mode)(verbose=True, **overrides)\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\", line 203, in train\n",
      "    self.trainer = self.TrainerClass(overrides=overrides)\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\", line 122, in __init__\n",
      "    self.data = check_det_dataset(self.data)\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\ultralytics\\yolo\\data\\utils.py\", line 201, in check_det_dataset\n",
      "    data = yaml_load(data, append_filename=True)  # dictionary\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\ultralytics\\yolo\\utils\\__init__.py\", line 430, in yaml_load\n",
      "    return {**yaml.safe_load(f), 'yaml_file': str(file)} if append_filename else yaml.safe_load(f)\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\__init__.py\", line 125, in safe_load\n",
      "    return load(stream, SafeLoader)\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\__init__.py\", line 81, in load\n",
      "    return loader.get_single_data()\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\constructor.py\", line 49, in get_single_data\n",
      "    node = self.get_single_node()\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\composer.py\", line 36, in get_single_node\n",
      "    document = self.compose_document()\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\composer.py\", line 55, in compose_document\n",
      "    node = self.compose_node(None, None)\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\composer.py\", line 84, in compose_node\n",
      "    node = self.compose_mapping_node(anchor)\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\composer.py\", line 127, in compose_mapping_node\n",
      "    while not self.check_event(MappingEndEvent):\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\parser.py\", line 98, in check_event\n",
      "    self.current_event = self.state()\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\parser.py\", line 428, in parse_block_mapping_key\n",
      "    if self.check_token(KeyToken):\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\scanner.py\", line 115, in check_token\n",
      "    while self.need_more_tokens():\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\scanner.py\", line 152, in need_more_tokens\n",
      "    self.stale_possible_simple_keys()\n",
      "  File \"f:\\pythonen\\yolo\\lib\\site-packages\\yaml\\scanner.py\", line 291, in stale_possible_simple_keys\n",
      "    raise ScannerError(\"while scanning a simple key\", key.mark,\n",
      "yaml.scanner.ScannerError: while scanning a simple key\n",
      "  in \"custom.yaml\", line 6, column 1\n",
      "could not find expected ':'\n",
      "  in \"custom.yaml\", line 7, column 1\n",
      "Sentry is attempting to send 1 pending events\n",
      "Waiting up to 2 seconds\n",
      "Press Ctrl-Break to quit\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=train model=yolov8m.pt data=custom.yaml epochs=200 imgsz=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398fdf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
